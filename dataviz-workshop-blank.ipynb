{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the Natural Language Processing Toolkit\n",
    "import nltk\n",
    "\n",
    "# Get the data science package Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Get the library matplotlib for making pretty charts\n",
    "import matplotlib as plt\n",
    "\n",
    "# Make plots appear here in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# This just makes the plot size bigger, so that we can see it easier. \n",
    "plt.rcParams['figure.figsize'] = (12,4)\n",
    "\n",
    "# Get all the example books from the NLTK textbook\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's explore these texts a little. \n",
    "# There are lots of things we can do with these texts. \n",
    "# To see a list, type text1. and press <Tab>\n",
    "text1.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# But what if we get tired of doing that for each text, and want to do it with all of them? \n",
    "# Put the texts into a list.\n",
    "alltexts = [text1, text2, text3, text4, text5, text6, text7, text8, text9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's look at it to make sure it's all there. \n",
    "alltexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for text in alltexts: \n",
    "    text.collocations()\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text6.concordance('shrubbery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text1.dispersion_plot(['Ahab', 'Ishmael', 'whale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text2.dispersion_plot(['Elinor', 'Marianne', 'Edward', 'Willoughby'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text6.dispersion_plot(['Ni', 'shrubbery'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's count the words in a text\n",
    "len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put the texts and their wordcounts into a lookup table\n",
    "lengths = {text.name: len(text) for text in alltexts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series(lengths).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# That in itself is not very interesting. \n",
    "# So let's see if we can not only count the words, but count the vocabulary\n",
    "# of a text.\n",
    "# To do that, we can use `set()`, which will count every word once. \n",
    "porky_sentence = \"the the the the the that's all folks\"\n",
    "porky_words = porky_sentence.split()\n",
    "porky_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can count the words in the sentence easily: \n",
    "len(porky_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To count the words, but ignore repeated words, we can use the function set(). \n",
    "set(porky_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# So if we count this set, we can determine the vocabulary of a text. \n",
    "len(set(porky_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's see if we can find the vocabulary of Moby Dick.\n",
    "len(set(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pretty big, but then again, Moby Dick is kind of a long novel. \n",
    "# We can adjust for the words by adjusting for the total words: \n",
    "len(text1) / len(set(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This would get tedious if we did this for every text, \n",
    "# so let's write a function!\n",
    "def vocab(text): \n",
    "    return len(text) / len(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab(porky_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's go through each text, and get its vocabulary, and put it in a table. \n",
    "vocabularies = {text.name: vocab(text) for text in alltexts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's put that table into Pandas so we can see it better: \n",
    "pd.Series(vocabularies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's plot that. \n",
    "pd.Series(vocabularies).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OK, now let's make a famous wordcloud\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawtext = ' '.join(text1.tokens) # Stitch it back together. \n",
    "wc = WordCloud(width=800, height=600, background_color='white')\n",
    "im = wc.generate(rawtext).to_image()\n",
    "plt.pyplot.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's take a look at the inaugural address corpus in detail. \n",
    "from nltk.corpus import inaugural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's set up a conditional word frequency distribution for it, \n",
    "# pairing off a list of words with the list of inaugural addresses. \n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "           (target, fileid[:4])\n",
    "           for fileid in inaugural.fileids()\n",
    "           for w in inaugural.words(fileid)\n",
    "           for target in ['america', 'citizen']\n",
    "           if w.lower().startswith(target))\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's play around with the Brown corpus. \n",
    "# It's a categorized text corpus. Let's see all the categories: \n",
    "nltk.corpus.brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's create another conditional frequency distribution, \n",
    "# this time based on these genres. \n",
    "genres = ['adventure', 'romance', 'science_fiction']\n",
    "words = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "cfdist = nltk.ConditionalFreqDist(\n",
    "              (genre, word)\n",
    "              for genre in genres\n",
    "              for word in nltk.corpus.brown.words(categories=genre)\n",
    "              if word in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(cfdist).T.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
